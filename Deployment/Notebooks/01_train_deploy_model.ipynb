{
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Copyright (c) Microsoft Corporation.\r\n",
        "\r\n",
        "Licensed under the MIT License."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "data_lake_account_name = ''\n",
        "file_system_name = ''\n",
        "\n",
        "subscription_id = \"\" \n",
        "resource_group = \"\" \n",
        "workspace_name = \"\" \n",
        "workspace_region = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "import azureml.core\n",
        "from azureml.core import Workspace, Experiment\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import logging\n",
        "import os\n",
        "\n",
        "from azureml.core.model import Model\n",
        "from azureml.core import Environment\n",
        "from azureml.core.model import InferenceConfig\n",
        "from azureml.core.webservice import AciWebservice\n",
        "from azureml.core.webservice import Webservice\n",
        "\n",
        "\n",
        "from azureml.core import Workspace\n",
        "ws = Workspace(workspace_name = workspace_name,\n",
        "               subscription_id = subscription_id,\n",
        "               resource_group = resource_group)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": true
      },
      "source": [
        "df_mapping = spark.read.format(\"csv\").load(f\"abfss://{file_system_name}@{data_lake_account_name}.dfs.core.windows.net/prepareddata/train\",header=True,escape ='\"',multiLine=True)\r\n",
        "df_mapping = df_mapping[['product','issue']].toPandas().drop_duplicates().sort_values(by='product')\r\n",
        "\r\n",
        "df_mapping.to_dict('records')\r\n",
        "df_mapping['product'].unique()\r\n",
        "\r\n",
        "\r\n",
        "df_train = spark.read.format(\"csv\").load(f\"abfss://{file_system_name}@{data_lake_account_name}.dfs.core.windows.net/prepareddata/train\",header=True,escape ='\"',multiLine=True)\r\n",
        "df_train.dtypes\r\n",
        "df_train = df_train.select('issue','complaint')\r\n",
        "df_train.write.option('header', 'true').mode('overwrite').csv(f'abfss://{file_system_name}@{data_lake_account_name}.dfs.core.windows.net/prepareddata/trainautoml/')\r\n",
        "\r\n",
        "df_train = df_train.toPandas()\r\n",
        "df_train['issue'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "diagram": {
          "activateDiagramType": 1,
          "chartConfig": {
            "category": "bar",
            "keys": [
              "issue"
            ],
            "values": [
              "count"
            ],
            "yLabel": "count",
            "xLabel": "issue",
            "aggregation": "SUM",
            "aggByBackend": false
          },
          "aggData": "{\"count\":{\"Advertising and marketing, including promotional offers\":1014,\"Attempts to collect debt not owed\":998,\"Can't repay my loan\":993,\"Closing an account\":994,\"Closing your account\":1006,\"Communication tactics\":1016,\"Cont'd attempts collect debt not owed\":1004,\"Credit monitoring or identity theft protection services\":954,\"Dealing with my lender or servicer\":1002,\"Dealing with your lender or servicer\":1019,\"Disclosure verification of debt\":1032,\"False statements or representation\":1000,\"Fees or interest\":1002,\"Getting a credit card\":1011,\"Getting a loan or lease\":957,\"Improper contact or sharing of info\":1001,\"Improper use of your report\":989,\"Incorrect information on your report\":992,\"Managing an account\":1015,\"Managing the loan or lease\":988,\"Opening an account\":936,\"Other features, terms, or problems\":1020,\"Problem caused by your funds being low\":1000,\"Problem when making payments\":1046,\"Problem with a credit reporting company's investigation into an existing problem\":978,\"Problem with a lender or other company charging your account\":1002,\"Problem with a purchase shown on your statement\":1008,\"Problems at the end of the loan or lease\":974,\"Struggling to pay your loan\":1034,\"Struggling to repay your loan\":1009,\"Taking/threatening an illegal action\":996,\"Threatened to contact someone or share information improperly\":1010,\"Took or threatened to take negative or legal action\":995,\"Trouble using your card\":983,\"Unable to get your credit report or credit score\":977,\"Written notification about debt\":1045}}",
          "isSummary": false,
          "previewData": {
            "filter": null
          },
          "isSql": false
        }
      },
      "source": [
        "df_train['issue'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "df_train.loc[:,'issue_id'] = pd.factorize(df_train['issue'])[0]\n",
        "df_train\n",
        "\n",
        "n_issues = len(df_train.issue.unique())\n",
        "print(\"n_issues:\", n_issues)\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "counts = vectorizer.fit_transform(df_train.issue)\n",
        "\n",
        "transformer = TfidfTransformer(smooth_idf=False)\n",
        "\n",
        "tfidf = transformer.fit_transform(counts)\n",
        "\n",
        "tfidf.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "test_size = max(int(np.floor(df_train.shape[0]*.1)), 2*n_issues)\n",
        "train_size = int((df_train.shape[0] - test_size) * 1.0)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(tfidf, \n",
        "                                                    df_train.issue, \n",
        "                                                    train_size=train_size, \n",
        "                                                    test_size=test_size,\n",
        "                                                    stratify=df_train.issue)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler(with_mean=False)\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "import numpy as np\n",
        "\n",
        "# larger C decreases runtime, but decreases performance\n",
        "\n",
        "C = 0.01\n",
        "print(\"C: %s\" % C)\n",
        "clf = LogisticRegression(C=C,\n",
        "                         multi_class='multinomial',\n",
        "                         penalty='l1', solver='saga', tol=0.2)\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "sparsity = np.mean(clf.coef_ == 0) * 100\n",
        "score = clf.score(X_test, y_test)\n",
        "print(\"Sparsity with L1 penalty: %.2f%%\" % sparsity)\n",
        "print(\"Test score with L1 penalty: %.4f\" % score)\n",
        "print(\"Chance performance is: %.4f\" % (1.0/y_train.unique().shape[0]))\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "from sklearn.metrics import precision_score\n",
        "\n",
        "y_test_pred = clf.predict(X_test)\n",
        "\n",
        "macro_prec = precision_score(y_test, y_test_pred, average='macro')\n",
        "micro_prec = precision_score(y_test, y_test_pred, average='micro')\n",
        "\n",
        "print('Avg Precision Micro: %03f, Macro: %03f' % (micro_prec, macro_prec))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "pipeline = Pipeline([('vectorizer', vectorizer), ('transformer', transformer), ('scaler', scaler), ('lr', clf)])\n",
        "pipeline.set_params(transformer__smooth_idf=False, scaler__with_mean=False, lr__C=.01) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "pipeline.fit(df_train.complaint, df_train.issue)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "pipeline.score(df_train.complaint, df_train.issue)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "import joblib\n",
        "\n",
        "model_filename = 'ccmmodel'\n",
        "\n",
        "joblib.dump(value=pipeline, filename=model_filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "from azureml.core.model import Model\n",
        "model_path = 'ccmmodel'\n",
        "model_name = \"ccmmodel\"\n",
        "registered_model = Model.register(model_path = model_path, # this points to a local file\n",
        "                       model_name = model_name, # name the model is registered as\n",
        "                       tags = {'type': \"classification\"}, \n",
        "                       description = \"Complaints Classifier\", \n",
        "                       workspace = ws)\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "i = 100\n",
        "test_df = pd.DataFrame({'complaint' : [df_train.complaint.values[i]], 'issue': [df_train.issue.values[i]]})\n",
        "probs = pipeline.predict_proba(test_df.complaint).flatten()\n",
        "top_categories = np.argsort(-probs)[:5]\n",
        "top_tpis = pipeline.classes_[top_categories].tolist()\n",
        "\n",
        "print('complaint:', test_df.complaint.values[0])\n",
        "print('ground truth:', test_df.issue.values)\n",
        "print('top 5 tpis:', top_tpis)\n",
        "print(\"correct: \", test_df.issue.values in top_tpis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "scoring_script = \"\"\"\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from azureml.core.model import Model\n",
        "#from sklearn.externals import joblib\n",
        "import joblib\n",
        "\n",
        "def init():\n",
        "    global pipeline\n",
        "    model_path = Model.get_model_path(model_name = 'ccmmodel')\n",
        "    pipeline = joblib.load(model_path)\n",
        "    \n",
        "def run(input_json):\n",
        "    mappinglist = [{'product': 'Banking Services', 'issue': 'Managing an account'}, {'product': 'Banking Services', 'issue': 'Opening an account'}, {'product': 'Banking Services', 'issue': 'Incorrect information on your report'}, {'product': 'Banking Services', 'issue': 'Unable to get your credit report or credit score'}, {'product': 'Banking Services', 'issue': 'Credit monitoring or identity theft protection services'}, {'product': 'Banking Services', 'issue': 'Closing an account'}, {'product': 'Banking Services', 'issue': 'Problem caused by your funds being low'}, {'product': 'Banking Services', 'issue': 'Problem with a lender or other company charging your account'}, {'product': 'Card Services', 'issue': 'Other features, terms, or problems'}, {'product': 'Card Services', 'issue': 'Closing your account'}, {'product': 'Card Services', 'issue': 'Advertising and marketing, including promotional offers'}, {'product': 'Card Services', 'issue': 'Problem with a purchase shown on your statement'}, {'product': 'Card Services', 'issue': 'Credit monitoring or identity theft protection services'}, {'product': 'Card Services', 'issue': 'Unable to get your credit report or credit score'}, {'product': 'Card Services', 'issue': 'Incorrect information on your report'}, {'product': 'Card Services', 'issue': 'Trouble using your card'}, {'product': 'Card Services', 'issue': \"Problem with a credit reporting company's investigation into an existing problem\"}, {'product': 'Card Services', 'issue': 'Improper use of your report'}, {'product': 'Card Services', 'issue': 'Problem when making payments'}, {'product': 'Card Services', 'issue': 'Getting a credit card'}, {'product': 'Card Services', 'issue': 'Fees or interest'}, {'product': 'Credit Reporting', 'issue': 'Credit monitoring or identity theft protection services'}, {'product': 'Credit Reporting', 'issue': 'Getting a loan or lease'}, {'product': 'Credit Reporting', 'issue': 'Improper use of your report'}, {'product': 'Credit Reporting', 'issue': \"Problem with a credit reporting company's investigation into an existing problem\"}, {'product': 'Credit Reporting', 'issue': 'Unable to get your credit report or credit score'}, {'product': 'Credit Reporting', 'issue': 'Incorrect information on your report'}, {'product': 'Debt Collection', 'issue': 'Disclosure verification of debt'}, {'product': 'Debt Collection', 'issue': 'Improper contact or sharing of info'}, {'product': 'Debt Collection', 'issue': 'False statements or representation'}, {'product': 'Debt Collection', 'issue': 'Communication tactics'}, {'product': 'Debt Collection', 'issue': 'Attempts to collect debt not owed'}, {'product': 'Debt Collection', 'issue': \"Cont'd attempts collect debt not owed\"}, {'product': 'Debt Collection', 'issue': 'Taking/threatening an illegal action'}, {'product': 'Debt Collection', 'issue': 'Written notification about debt'}, {'product': 'Debt Collection', 'issue': 'Took or threatened to take negative or legal action'}, {'product': 'Debt Collection', 'issue': 'Threatened to contact someone or share information improperly'}, {'product': 'Loans', 'issue': 'Dealing with my lender or servicer'}, {'product': 'Loans', 'issue': 'Managing the loan or lease'}, {'product': 'Loans', 'issue': 'Struggling to repay your loan'}, {'product': 'Loans', 'issue': 'Getting a loan or lease'}, {'product': 'Loans', 'issue': 'Problems at the end of the loan or lease'}, {'product': 'Loans', 'issue': 'Unable to get your credit report or credit score'}, {'product': 'Loans', 'issue': \"Problem with a credit reporting company's investigation into an existing problem\"}, {'product': 'Loans', 'issue': 'Credit monitoring or identity theft protection services'}, {'product': 'Loans', 'issue': 'Improper use of your report'}, {'product': 'Loans', 'issue': 'Dealing with your lender or servicer'}, {'product': 'Loans', 'issue': \"Can't repay my loan\"}, {'product': 'Loans', 'issue': 'Incorrect information on your report'}, {'product': 'Loans', 'issue': 'Struggling to pay your loan'}]\n",
        "    df_mapping = pd.DataFrame(mappinglist,columns=['product','issue'])\n",
        "    df_mapping_dict = dict(zip(df_mapping['issue'],df_mapping['product']))\n",
        "\n",
        "    data_df = pd.read_json(input_json, orient='records')\n",
        "    probs = pipeline.predict_proba(data_df.complaint).flatten()\n",
        "    top_probs = np.argsort(-probs)[:5]\n",
        "    top_probs.sort()\n",
        "    top_probs = top_probs[::-1]\n",
        "    top_issues = pipeline.classes_[top_probs].tolist()\n",
        "    top_products = [df_mapping_dict[issue] for issue in top_issues]\n",
        "    columns = ['class1','class2','class3','class4','class5','subclass1','subclass2','subclass3','subclass4','subclass5','subclass1_score','subclass2_score','subclass3_score','subclass4_score','subclass5_score']\n",
        "    df_result = pd.DataFrame(None, columns = columns) \n",
        "    df_result.loc[len(df_result)] = np.append(np.append(top_products,top_issues),top_probs)\n",
        "    return {'predictions': df_result.to_dict(orient='records')[0]}\n",
        "\"\"\"\n",
        "\n",
        "exec(scoring_script)\n",
        "with open(\"scoring_script.py\", \"w\") as file:\n",
        "    file.write(scoring_script)\n",
        "    \n",
        "scoring_script_file_name = 'scoring_script.py'\n",
        "\n",
        "#test locally\n",
        "json_test_data = df_train.head(1).to_json(orient='records')\n",
        "print(json_test_data)\n",
        "init()\n",
        "run(json_test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "from azureml.core.conda_dependencies import CondaDependencies \n",
        "\n",
        "# Add the dependencies for our model (AzureML defaults is already included)\n",
        "myenv = CondaDependencies()\n",
        "myenv.add_conda_package('scikit-learn=0.22.2.post1')\n",
        "myenv.add_conda_package('joblib')\n",
        "myenv.add_pip_package(\"azureml-model-management-sdk\")\n",
        "myenv.add_pip_package(\"pandas\")\n",
        "myenv.add_pip_package(\"numpy\")\n",
        "\n",
        "\n",
        "# Save the environment config as a .yml file\n",
        "env_file = \"my_env.yml\"\n",
        "with open(env_file,\"w\") as f:\n",
        "    f.write(myenv.serialize_to_string())\n",
        "print(\"Saved dependency info in\", env_file)\n",
        "\n",
        "# Print the .yml file\n",
        "with open(env_file,\"r\") as f:\n",
        "    print(f.read())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "from azureml.core.webservice import AciWebservice\n",
        "from azureml.core.model import InferenceConfig\n",
        "\n",
        "# Configure the scoring environment\n",
        "inference_config = InferenceConfig(runtime= \"python\",\n",
        "                                   entry_script=scoring_script_file_name,\n",
        "                                   conda_file=env_file)\n",
        "\n",
        "deployment_config = AciWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 1)\n",
        "\n",
        "service_name = \"ccm-service-3\"\n",
        "\n",
        "service = Model.deploy(ws, service_name, [registered_model], inference_config, deployment_config)\n",
        "\n",
        "service.wait_for_deployment(show_output =True)\n",
        "print(service.state)"
      ]
    }
  ],
  "metadata": {
    "save_output": false,
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    }
  }
}